<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Mles.io</title>
<link href="css/style.css" rel="stylesheet"></link>
<style>
#bwidth {
    margin: auto;
    width: 85%;
    padding: 10px;
}
</style>
</head>
<body>
<div class="container">
<div id="bwidth">
<div>
<img src="images/mles_logo_final.png" alt="Mles logo" width="100" />
</div>
<p><b>Mles</b> (<i>Modern Lightweight channEl Service</i>) is a lightweight, robust and authenticated distributed publish-subscribe data service based on Rust (a safe, concurrent and fast systems language), Tokio (asynchronous networking for Rust) and Serde (serialization framework for Rust). It works seamlessly with IPv4 and IPv6 on TCP, which provides its reliable data transfer backbone on Rust supported platforms, including Linux, macOS and Windows.</p>

<h2>Why Mles?</h2>

<p>Mles provides a way to build a publish-subscribe service between clients which need a channel to exchange messages on in a reliable manner. Every connection also identifies the channel which provides an easy way for clients to open and close connections without additional messaging: just connect and send, and when done, close the connection. With advanced connection handling on top of Tokio futures, Mles should scale well even with a large number of connections. Clients may choose their internal data structure freely as it is transparent to Mles. Mles relies on a modern authentication mechanism which should perform well even with short inputs. Due to the lightweight design on Rust, the performance of Mles should be an improvement compared to existing options (see Fig. 1).<br />
<img src="images/simple_performance_comparison.png" alt="Simple performance comparison" vspace="20" /><br /><b>Figure 1.</b> Performance comparison between RabbitMQ and Mles</p>

<h2>Mles overview</h2>

<p>Mles is based on <i>Mles protocol</i> (IANA port# 8077) which has a 16 byte header + key structure with SipHash based authentication. The reference server implementation is fully safe Rust, lock-free (no blocking!) and supports strong session authentication between Mles client and server. With its two-layer authentication scheme (1st level: server-client, 2nd level: client-client) it provides a possibility for clients to authenticate each other independently from servers and also to build any additional protocol over Mles they may need. I.e. the clients may choose any data structure they wish to exchange messages with each other on top of Mles protocol.</p>


<p>Mles data structure is based on CBOR (Concise Binary Object Representation). It consists of (<i>uid, channel, message</i>) value triplet where <i>uid</i> and <i>channel</i> are UTF-8 strings and <i>message</i> can be of any type of payload with a maximum size of 16.7 MB. This is the only mandatory message type that a client should be aware of. Additional internal message types like "join" or "leave" messages that would be forwarded internally do not exist. Moreover, Mles protocol does not have any flags by design which simplifies the message handling itself. In practice, after the first frame is authenticated, Mles server just forwards the next frames to all subscribers. Please see the Mles protocol header below.<br />
<img src="images/mles_header_key.png" alt="Mles header key"  />
</p>

<p>Mles example client provides basic Tokio based client implementation and includes also a simple WebSocket proxy which allows using Mles without opening additional public port, if that is not in some cases feasible.</p>

<p>Mles protocol and reference implementation are stable with v1.0 release. Please have a look at the API <a href="https://docs.rs/mles-utils/1.1.5/mles_utils/">here</a>. For more information about Mles reference implementation, see <a href="https://github.com/jq-rs/mles-rs">https://github.com/jq-rs/mles-rs</a> and the <a href="https://mles.io/blog.html">blog</a> which has more details about the measured performance figures too.</p>

<h2>Advanced features: Mles peers and message history</h2>

<p>Mles servers may be connected by defining peer servers. A peer is a Mles server that is configured to be connected to another server and where clients can connect to. A peer forwards all client messages to their peer server and back. The Mles server sees the peer connection as just another client. This provides a simple but yet powerful way to distribute data between servers. The server, peers and clients form a tree-like structure to exchange messages. As it is possible to configure peers to a loop by accident, the Mles protocol provides loop protection with help of unique connection id (CID).</p>

<p>Mles servers and peers may also provide history information which provides a message history for new client connections. Compared to other protocols, Mles server does not try to hold a queue of messages and monitor the state of each message when has it reached all subscribers and can be removed from the queue. Instead, Mles server just resends the history available to lost and reconnected clients (which can be peers too). This makes the processing logic smooth and lightweight. The end result is that a client is guaranteed to receive all history information on the channel in case of connection loss when the client can reconnect. The client is also able to compare has there been new messages on the channel while the connection was lost. Based on the message history, the client can also figure out are some of its own sent messages lost and do they need resending. Naturally, not all clients need all these features which is one reason why Mles does not try to implement them for the clients.</p>

<p>In addition to distribution, the peers provide a way to offer resilience with resynchronisation message for the channel history information in case e.g. Mles root server restart during an upgrade. Clients may ignore this resynchronization messaging. Still, an API is available for them to provide similar resynchronization for Mles servers if needed.</p>

<h2>Use cases</h2>

<p>It is important that any data can be distributed in a scalable and properly authenticated but still reliable way. These services can take advantage of using Mles as a backbone service. In a simple use case several clients are connected directly to a public server on their chosen channel (see Fig. 2).<br /><br />
<img src="images/mles_usecase_with_clients_trans.png" alt="Mles use case with client" /><br /><b>Figure 2.</b> Mles use case with directly connected clients<br />
</p>
<p>Another common use case is with more servers, a public server and a peer server. Clients may connect either to the peer or to the public server directly (see Fig. 3).<br /><br /><img src="images/mles_usecase_with_peer_trans.png" alt="Mles use case with peer" />
<br /><b>Figure 3.</b> Mles use case with a peer<br />
</p>
<p>Any tree-like setup where you have a Mles server should work just fine.</p>

<p>Services that could have the benefit of the Mles could be e.g. configuration distribution or IoT telemetry. In general, any publish-subscribe service without the need of database on the service itself can be seen as a fine candidate as a use case, especially if it has a large number of clients with a limited number of channels to subscribe. As the mechanism for joining a channel is always per connection and channels cannot be multiplexed on the same connection, Mles may not be the best choice for a client which needs to connect to a very large number of channels. It is, however, possible to use a WebSocket connection over <a href="https://github.com/jq-rs/mles-webproxy">Mles WebProxy</a> which does the TCP connection bundling for the WebSocket client and the client can multiplex several channels on a single WebSocket connection.</p>

<h2>Design notes on client layer protocol</h2>

<p>Implementing a light client for Mles is straightforward as the client only needs to know which kind of data structure to use between other clients. However, with history information enabled, the client should expect the duplication of already received messages in case of errors on the data path where Mles is run. This should be taken into account while designing a client layer protocol. An easy way to identify retransmitted messages is to add a sequence number per user to the client layer protocol. Advanced clients could add this sequence number on 8 bytes SipHash key-field, after the initial authentication is done. This sequence number can be then used to identify already received messages and ignore them when necessary. It is also good to notice, that even though Mles is run on TCP which provides reliable streaming data service, it does not protect from data loss in case of a forwarding path failure. A client should be able to resynchronize to history and able to resend lost messages in case such reliability is needed.</p> 

<p>Clients may also need to know who has subscribed current channel. To have this information, clients may monitor it from initial frames which are sent during a connection attempt to channel: even though the first authenticated message would be empty, this empty message with <i>uid</i> and <i>channel</i> information is received by all connected clients. If channel depart information is needed, either an own depart messaging can be designed, or a keepalive mechanism can be introduced on top of client layer protocol.</p> 

<p>In case needed, clients can be implemented on top of Mles-WebSocket protocol in similar manner. An open-source proof-of-concept client that has all of above concepts implemented is used in <a href="https://mles.io/app.html">MlesTalk</a> application.</p>

<h2>Future development</h2>

<p>In the future, the reference implementation may be enhanced with performance and resiliency improvements. Other extensions may be considered too as long as they do not change the general principles of Mles.<p>

<p>Changes to the Mles protocol itself are not allowed after 1.0 release as a simple protocol means lightweight, compatible and understandable service. It may be sent to standardization to guarantee this.</p>

<p>On client side, of course, any new type of service can be introduced as a 2nd level service. New client layer protocol implementations are welcome to be shared as examples, please send a note or a PR (and ask for a review for your crate too) if you invent such!</p>
<br />
</div>
</div>
</body>
</html>


